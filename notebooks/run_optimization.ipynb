{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 14:01:11.537321: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-11 14:01:11.688697: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-11 14:01:12.381077: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.1/lib64:/usr/local/cuda-11.1/lib64\n",
      "2023-01-11 14:01:12.381134: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.1/lib64:/usr/local/cuda-11.1/lib64\n",
      "2023-01-11 14:01:12.381140: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import f3dasm\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 14:01:21.174578: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-01-11 14:01:21.174628: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (martin): /proc/driver/nvidia/version does not exist\n",
      "2023-01-11 14:01:21.175643: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "dim = 3\n",
    "iterations = 50\n",
    "realizations = 3\n",
    "bounds = np.tile([-1.0,1.0], (dim, 1))\n",
    "hyperparameters={}\n",
    "#hyperparameters={'learning_rate': 1e-2}\n",
    "\n",
    "design = f3dasm.make_nd_continuous_design(bounds=bounds, dimensionality=dim)\n",
    "\n",
    "function = f3dasm.functions.Levy(dimensionality=dim, scale_bounds=bounds, seed=42, noise=0.3)\n",
    "\n",
    "data = f3dasm.Data(design=design)\n",
    "optimizer = f3dasm.optimization.Adam(data=data, hyperparameters=hyperparameters)\n",
    "sampler = f3dasm.sampling.LatinHypercube(design=design)\n",
    "\n",
    "\n",
    "# all_data = f3dasm.run_multiple_realizations(optimizer=optimizer, \n",
    "# function=function,\n",
    "# sampler=sampler,\n",
    "# iterations=iterations,\n",
    "# realizations=realizations\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam_Parameters(population=1, force_bounds=True, learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Mul as input #1(zero-based) was expected to be a double tensor but is a float tensor [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m args \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m \u001b[39m'\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m'\u001b[39m: optimizer, \n\u001b[1;32m      3\u001b[0m \u001b[39m'\u001b[39m\u001b[39mfunction\u001b[39m\u001b[39m'\u001b[39m: function,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m }\n\u001b[0;32m---> 11\u001b[0m res \u001b[39m=\u001b[39m f3dasm\u001b[39m.\u001b[39;49mrun_optimization(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/Documents/GitHub/F3DASM/src/f3dasm/run_optimization.py:118\u001b[0m, in \u001b[0;36mrun_optimization\u001b[0;34m(optimizer, function, sampler, iterations, seed, number_of_samples)\u001b[0m\n\u001b[1;32m    115\u001b[0m optimizer\u001b[39m.\u001b[39mset_data(samples)\n\u001b[1;32m    117\u001b[0m \u001b[39m# Iterate\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m optimizer\u001b[39m.\u001b[39;49miterate(iterations\u001b[39m=\u001b[39;49miterations, function\u001b[39m=\u001b[39;49mfunction)\n\u001b[1;32m    119\u001b[0m res \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mextract_data()\n\u001b[1;32m    121\u001b[0m \u001b[39m# Reset the parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/F3DASM/src/f3dasm/optimization/optimizer.py:187\u001b[0m, in \u001b[0;36mOptimizer.iterate\u001b[0;34m(self, iterations, function)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_number_of_datapoints()\n\u001b[1;32m    186\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(_number_of_updates(iterations, population\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameter\u001b[39m.\u001b[39mpopulation)):\n\u001b[0;32m--> 187\u001b[0m     x, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_step(function\u001b[39m=\u001b[39;49mfunction)\n\u001b[1;32m    188\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_iteration_to_data(x, y)\n\u001b[1;32m    190\u001b[0m \u001b[39m# Remove overiterations\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/F3DASM/src/f3dasm/optimization/adapters/tensorflow_implementations.py:36\u001b[0m, in \u001b[0;36mTensorflowOptimizer.update_step\u001b[0;34m(self, function)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_step\u001b[39m(\u001b[39mself\u001b[39m, function: Function) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mndarray]:\n\u001b[1;32m     34\u001b[0m     \u001b[39m# autograd_func = convert_autograd_to_tensorflow(function.__call__)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mget_input_data()\u001b[39m.\u001b[39miloc[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto_numpy()\n\u001b[0;32m---> 36\u001b[0m     grads \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39;49mdfdx(x)\n\u001b[1;32m     37\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(grads, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs[\u001b[39m\"\u001b[39m\u001b[39mtvars\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[1;32m     39\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39m+\u001b[39m tf\u001b[39m.\u001b[39mcast(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m](\u001b[39mNone\u001b[39;00m), tf\u001b[39m.\u001b[39mfloat64)\n",
      "File \u001b[0;32m~/Documents/GitHub/F3DASM/src/f3dasm/base/function.py:135\u001b[0m, in \u001b[0;36mFunction.dfdx\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    131\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m](\u001b[39mNone\u001b[39;00m)  \u001b[39m# tf.cast(self.args[\"model\"](None), tf.float64)\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs[\u001b[39m\"\u001b[39m\u001b[39mfunc\u001b[39m\u001b[39m\"\u001b[39m](tf\u001b[39m.\u001b[39mreshape(\n\u001b[1;32m    133\u001b[0m         logits, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdimensionality)))\n\u001b[0;32m--> 135\u001b[0m grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39;49mgradient(loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs[\u001b[39m\"\u001b[39;49m\u001b[39mtvars\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    136\u001b[0m \u001b[39mreturn\u001b[39;00m grads[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/miniconda3/envs/f3dasm_env3/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py:1112\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1106\u001b[0m   output_gradients \u001b[39m=\u001b[39m (\n\u001b[1;32m   1107\u001b[0m       composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1108\u001b[0m           output_gradients))\n\u001b[1;32m   1109\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1110\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1112\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[1;32m   1113\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[1;32m   1114\u001b[0m     flat_targets,\n\u001b[1;32m   1115\u001b[0m     flat_sources,\n\u001b[1;32m   1116\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[1;32m   1117\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[1;32m   1118\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[1;32m   1120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[1;32m   1121\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m~/miniconda3/envs/f3dasm_env3/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[1;32m     68\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m     target,\n\u001b[1;32m     70\u001b[0m     sources,\n\u001b[1;32m     71\u001b[0m     output_gradients,\n\u001b[1;32m     72\u001b[0m     sources_raw,\n\u001b[1;32m     73\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[0;32m~/miniconda3/envs/f3dasm_env3/lib/python3.8/site-packages/tensorflow/python/ops/custom_gradient.py:586\u001b[0m, in \u001b[0;36m_eager_mode_decorator.<locals>.actual_grad_fn\u001b[0;34m(*result_grad_components)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMust return gradient for each variable from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    584\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m@custom_gradient grad_fn.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    585\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 586\u001b[0m   input_grads \u001b[39m=\u001b[39m grad_fn(\u001b[39m*\u001b[39;49mresult_grads)\n\u001b[1;32m    587\u001b[0m   variable_grads \u001b[39m=\u001b[39m []\n\u001b[1;32m    588\u001b[0m flat_grads \u001b[39m=\u001b[39m composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m    589\u001b[0m     nest\u001b[39m.\u001b[39mflatten(input_grads))\n",
      "File \u001b[0;32m~/Documents/GitHub/F3DASM/src/f3dasm/base/utils.py:157\u001b[0m, in \u001b[0;36mconvert_autograd_to_tensorflow.<locals>.wrapper.<locals>.first_grad\u001b[0;34m(dy)\u001b[0m\n\u001b[1;32m    154\u001b[0m     vjp2, ans2 \u001b[39m=\u001b[39m autograd\u001b[39m.\u001b[39mcore\u001b[39m.\u001b[39mmake_vjp(egrad(func), a\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m    155\u001b[0m     \u001b[39mreturn\u001b[39;00m ans2, vjp2  \u001b[39m# hessian\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m \u001b[39mreturn\u001b[39;00m dy \u001b[39m*\u001b[39;49m jacobian(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/f3dasm_env3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/f3dasm_env3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:7215\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7214\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7215\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Mul as input #1(zero-based) was expected to be a double tensor but is a float tensor [Op:Mul]"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "'optimizer': optimizer, \n",
    "'function': function,\n",
    "'sampler': sampler,\n",
    "'iterations': iterations,\n",
    "'seed': 1\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "res = f3dasm.run_optimization(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function.plot_data(data=res,domain=bounds)\n",
    "xv, yv, Y = function._create_mesh(px=300,domain=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function.plot(px=100, domain=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f3dasm.write_pickle('Levyfunction_2D', Y)\n",
    "\n",
    "Y_check = f3dasm.read_pickle('Levyfunction_2D')\n",
    "\n",
    "assert (Y_check == Y).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = {\n",
    "# 'realizations': realizations,\n",
    "# 'optimizer': optimizer, \n",
    "# 'function': function,\n",
    "# 'sampler': sampler,\n",
    "# 'iterations': iterations,\n",
    "# 'parallelization': True\n",
    "\n",
    "\n",
    "# }\n",
    "# f3dasm.run_multiple_realizations(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Run multiple realizations of the same algorithm on a benchmark function\"\"\"\n",
    "# start_t = time.perf_counter()\n",
    "\n",
    "# seed = np.random.randint(low=0, high=1e5)\n",
    "# all_data = []\n",
    "\n",
    "# for _ in range(realizations):\n",
    "#     data = f3dasm.run_optimization(\n",
    "#         optimizer=optimizer, function=function, sampler=sampler, iterations=iterations, seed=seed\n",
    "#     )\n",
    "#     all_data.append(data)\n",
    "\n",
    "#     # Increase seed\n",
    "#     seed += 1\n",
    "\n",
    "# end_t = time.perf_counter()\n",
    "\n",
    "# total_duration = end_t - start_t\n",
    "# print(f\"Optimization took {total_duration:.2f}s total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathos.helpers import mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run multiple realizations of the same algorithm on a benchmark function\"\"\"\n",
    "start_t = time.perf_counter()\n",
    "\n",
    "args = [(optimizer, function,  sampler, iterations, np.random.randint(low=0, high=1e5)) for _ in range(realizations)]\n",
    "\n",
    "\n",
    "\n",
    "with mp.Pool() as pool:\n",
    "    results = pool.starmap(f3dasm.run_optimization, args)\n",
    "    \n",
    "end_t = time.perf_counter()\n",
    "\n",
    "total_duration = end_t - start_t\n",
    "print(f\"Optimization took {total_duration:.2f}s total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function.plot_data(data=results[1], domain=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run multiple realizations of the same algorithm on a benchmark function\"\"\"\n",
    "start_t = time.perf_counter()\n",
    "\n",
    "args = [(optimizer, function,  sampler, iterations, np.random.randint(low=0, high=1e5)) for _ in range(realizations)]\n",
    "\n",
    "\n",
    "with Pool() as pool:\n",
    "    results = pool.starmap_async(f3dasm.run_optimization, args)\n",
    "    \n",
    "end_t = time.perf_counter()\n",
    "\n",
    "total_duration = end_t - start_t\n",
    "print(f\"Optimization took {total_duration:.2f}s total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.dfdx(np.array([0.5, 0.8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dim == 2:\n",
    "    fig, ax = func.plot_data(all_data[0], px=100, domain=bounds)\n",
    "    ax.scatter(func.get_global_minimum(dim)[0][0],func.get_global_minimum(dim)[0][1], s=40, c='r')\n",
    "    #ax.scatter(-3.19468541,0.89682456, s=40, c='g')\n",
    "    func.plot(px=100, domain=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[0.2,0.1],[0.3,0.4]])\n",
    "y + np.abs(func.get_global_minimum(2)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[0].data['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.scale_bounds, func.input_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mean_y = pd.concat([d.get_output_data() for d in all_data], axis=1).mean(axis=1)\n",
    "std_y = pd.concat([d.get_output_data() for d in all_data], axis=1).std(axis=1)\n",
    "mean_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.figure(), plt.axes()\n",
    "ax.plot(mean_y)\n",
    "ax.fill_between(np.arange(len(mean_y)), mean_y-1.96*std_y, mean_y+1.96*std_y, color='b', alpha=.1)\n",
    "#ax.set_yscale('log')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.get_global_minimum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.descale_input(np.array([0.0,0.0]))\n",
    "x = np.array([[0.0,0.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.input_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(func.input_domain[:, 1] - func.input_domain[:, 0]) * x + func.input_domain[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x - func.input_domain[:, 0]) / (func.input_domain[:, 1] - func.input_domain[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.input_domain[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x - func.input_domain[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(func.input_domain[:, 1] - func.input_domain[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = np.array([[0.9,0.3]])\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.scale_input(func.descale_input(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.descale_input(func.scale_input(o))\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_bounds = [-3., 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = np.random.uniform(low=scale_bounds[0], high=scale_bounds[1], size=(1, func.dimensionality))\n",
    "x = o\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(func.input_domain[:, 1] - func.input_domain[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x - func.scale_bounds[:, 0]) / (func.scale_bounds[:, 1] - func.scale_bounds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.get_global_minimum(2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(func.scale_bounds[:, 1] - func.scale_bounds[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('f3dasm_env3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03276761335d5ee93b82dc97db1addd68180a543fb0cacb8af76ec058b1972b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
