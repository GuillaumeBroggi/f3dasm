{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 14:19:52.522874: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from f3dasm.functions.pybenchfunction import Sphere\n",
    "\n",
    "import autograd\n",
    "import autograd.core\n",
    "import autograd.numpy as np\n",
    "from autograd import elementwise_grad as egrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = Sphere(dimensionality=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_autograd_to_tensorflow(func):#S:func is completely written in numpy autograd\n",
    "    @tf.custom_gradient\n",
    "    def wrapper(x):\n",
    "        vjp, ans = autograd.core.make_vjp(func, x.numpy())\n",
    "        def first_grad(dy):            \n",
    "            @tf.custom_gradient\n",
    "            def jacobian(a):\n",
    "                vjp2, ans2 =  autograd.core.make_vjp(egrad(func), a.numpy())\n",
    "                return ans2,vjp2 # hessian                    \n",
    "\n",
    "            return dy* jacobian(x)  \n",
    "        return ans, first_grad\n",
    "    \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, seed=None, args=None):\n",
    "    super().__init__()\n",
    "    self.seed = seed\n",
    "    self.env = args\n",
    "\n",
    "######################### Pixel Model Class\n",
    "class PixelModel(Model):\n",
    "  \"\"\"\n",
    "    The class for performing optimization in the input space of the functions.\n",
    "    The initial parameters are chosen uniformly from [0,1] so as to ensure\n",
    "        similarity across all functions\n",
    "    TODO: May need to add the functionality to output denormalized bounds\n",
    "  \"\"\"\n",
    "  def __init__(self, seed=None, args = None):\n",
    "    super().__init__(seed)\n",
    "    z_init = tf.random.uniform((1,args['dim']), minval = 0, maxval = 1.0)\n",
    "    self.z = tf.Variable(z_init, trainable=True, dtype = tf.float32)#S:ADDED \n",
    "\n",
    "  def call(self, inputs=None):\n",
    "    return self.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 14:19:55.412938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = PixelModel(None,args={'dim': 2}) # Build the model\n",
    "fval = []   # To store the function values at each optimziation step   \n",
    "outs = []   #Storing teh outputs of the model (normalized!!) \n",
    "tvars = model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = convert_autograd_to_tensorflow(function.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[81.98852771]])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func(tf.cast(model(None), tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-69.74437, 171.82608]], dtype=float32)>],\n",
       " <tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[81.98852771]])>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(tvars)\n",
    "    logits = 0.0 + tf.cast(model(None), tf.float64)           \n",
    "    loss = func(tf.reshape(logits, (function.dimensionality)))\n",
    "grad = tape.gradient(loss,tvars)\n",
    "grad, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.apply_gradients(zip(grad, tvars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max_iterations + 1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(tvars)\n",
    "        logits = 0.0 + tf.cast(model(None), tf.float64)           \n",
    "        loss = func(tf.reshape(logits, (function.dimensionality)))\n",
    "\n",
    "    # fval.append(loss.numpy().copy())\n",
    "    # outs.append(logits.numpy()[0].copy())\n",
    "\n",
    "    grads = tape.gradient(loss, tvars)\n",
    "    optimizer.apply_gradients(zip(grads, tvars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[0.3915852 , 0.31545168]], dtype=float32)>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.39192986, 0.17665298]]), array([[0.]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function.get_global_minimum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.03015207]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.numpy().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.37928748]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function(np.array([0.0,0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39158124, 0.31579649]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.numpy().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd4aa09bf73c11ef3239c620489b85906b4cadb309e0ddddf54fa55967002edb"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 ('f3dasm_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
