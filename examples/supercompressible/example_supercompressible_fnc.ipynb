{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supercompressible (3d)\n",
    "\n",
    "L. F. Pereira (lfpereira@fe.up.pt)\\\n",
    "September 30, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we got here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to \"protect\" our Python installation, we created a `conda environmnent`:\n",
    "\n",
    "```shell\n",
    ">> conda create -n f3dasm_env python=3.8 jupyter nb_conda scipy matplotlib\n",
    "```\n",
    "\n",
    "The conda distribution installation can be found e.g. [here](https://docs.conda.io/en/latest/miniconda.html).\n",
    "\n",
    "We got access to this notebook after cloning this GitHub [repository](https://github.com/lpereira95/F3DAS):\n",
    "\n",
    "```shell\n",
    ">> git clone https://github.com/lpereira95/F3DAS\n",
    "```\n",
    "\n",
    "We opened the notebook by changing to the correct environment and writing down `jupyter notebook`:\n",
    "\n",
    "```shell\n",
    ">> conda activate f3dasm_env\n",
    ">> jupyter notebook\n",
    "```\n",
    "\n",
    "For the next steps, we admit there is an **Abaqus** installation in the system and available licences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook applies the data-driven framework to the supercompressible problem (see definition below). It comprises the following steps:\n",
    "1. Design of experiments\n",
    "2. Numerical simulations\n",
    "\n",
    "The numerical models were developed in **Abaqus** and are based on simple Python scripts that can be obtained e.g. from .rpy files. `f3dasm` also contains its own Abaqus development modules, but for the sake of simplicity they will not be mentioned today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/supercompressible.jpg\" width=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The supercompressible metamaterial is parameterized by **7 geometric parameters** and **2 material parameters**. \n",
    "\n",
    "The **geometry** is defined by the top and bottom diameters, $D_1$ and $D_2$, the height $P$ and the cross-section parameters of the vertical longerons: the cross-sectional area $A$, moments of inertial $I_x$ and $I_y$, and torsional constant $J$. \n",
    "\n",
    "The **isotropic material** is defined by its elastic constants: Young's modulus $E$ and shear modulus $G$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the principle of superposition both the geometric and material parameters can be scaled by one of its dimensions/properties (here $D_1$ and $E$). Therefore, the variables that you will find in the dataset are:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{D_1-D_2}{D_1},\\ \\frac{P}{D_1},\\ \\frac{I_x}{D_1^4},\\ \\frac{I_y}{D_1^4},\\ \\frac{J}{D_1^4},\\ \\frac{A}{D_1^2}, \\frac{G}{E}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a 7-dimensional problem and learning the response surface may require a significant amount of training points (remember the ``curse of dimensionality''!). Therefore, you will instead consider a simpler version of the problem in **3 dimensions**, through constraining the longerons' cross-section to be circular with diameter $d$, and choosing a particular material, leading to the following 3 features:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{d}{D_1},\\ \\frac{D_2-D_1}{D_1},\\ \\frac{P}{D_1}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **each data point** (i.e. for each material design) we can use **nonlinear finite element analyses** to predict the complete buckling and post-buckling behavior. From the analyses, we can understand if a material **is coilable** and compute the **critical buckling stress** $\\sigma_{crit}$ (defined as the critical buckling load divided by the area of the bottom ring of the metamaterial) and the **energy absorbed** $E_{abs}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand better which are the outputs from the numerical analyses, let's consider sample results data obtained with the following parameters:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{d}{D_1}=0.0040,\\ \\frac{D_2-D_1}{D_1}=0.00,\\ \\frac{P}{D_1}=0.2500\n",
    "\\end{equation*}\n",
    "\n",
    "The other parameters are according to the values fixed below (`fixed_variables`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# standard library\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# third-party\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# local\n",
    "from abaqus_modules.get_results import get_results_lin_buckle\n",
    "from abaqus_modules.get_results import read_and_clean_results_riks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the required data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('sample_data', 'DoE_point0.pkl'), 'rb') as file:\n",
    "    data_sim = pickle.load(file, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two output variables (coilability and $\\sigma_{crit}$) result from a **linear buckling analyses**.\n",
    "\n",
    "**Coilability** is simply an integer, which tells if the material is **coilable** or not. If the material is coilable, there's a further categorization to distinguish between materials that **yield** from those who not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coilable, sigma_crit = get_results_lin_buckle(data_sim)\n",
    "\n",
    "print('coilability: {}'.format(coilable))\n",
    "print('sigma_crit: {:.6f}'.format(sigma_crit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The energy absorbed $E_{abs}$ is computed from the output of a **Riks analysis** that follows the linear buckling analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (strain, stress), (energy, (x, y)), _ = read_and_clean_results_riks(data_sim, get_energy=True)\n",
    "\n",
    "# print info\n",
    "print('energy absorbed: {:.6f}'.format(energy))\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(strain, stress, label='FEM')\n",
    "ax.plot(x, y, label='interpolation')\n",
    "ax.set_xlabel('Strain')\n",
    "ax.set_ylabel('Stress /KPa')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `f3dasm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`f3dasm` is the in-house **Python library** to manage the application of the data-driven framework. The code is still under development, but an initial version can already be installed through `pip` (it can be installed as any other Python package, e.g. `pip install f3dasm`). The code is open-source and can be found in github *temporarily* on https://github.com/lpereira95/f3dasm; it will be soon moved to https://github.com/bessagroup/F3DASM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, let's import the required Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# standard library\n",
    "import os\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "# third-party\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from f3dasm.run.utils import create_main_file\n",
    "from f3dasm.run.utils import create_sim_info\n",
    "from f3dasm.run.abaqus import run_sims\n",
    "from f3dasm.run.stats import analyze_times\n",
    "from f3dasm.design_of_experiments import create_doe\n",
    "\n",
    "# local library\n",
    "from abaqus_modules.get_results import get_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the example name and the number of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_name = 'example_0'\n",
    "\n",
    "n_pts = 10  # number of points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick verification of the chosen name will be performed to avoid overriding existing folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(example_name):\n",
    "    raise Exception('Name already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable definition and  design of experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the **variables of the problem**, both the variables that are defined by the design of experiments scheme and the fixed variables (i.e. the variables that are common for all simulations).\n",
    "\n",
    "**Note**: the use of an ```OrderedDict``` is not mandatory, but forces variable order in the ```Pandas``` frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doe_variables = OrderedDict({'ratio_d': [0.004, 0.073],\n",
    "                             'ratio_pitch': [.25, 1.5],\n",
    "                             'ratio_top_diameter': [0., 0.8]})\n",
    "fixed_variables = {'n_longerons': 3,\n",
    "                   'bottom_diameter': 100.,\n",
    "                   'young_modulus': 3500.,\n",
    "                   'shear_modulus': 1287.,}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using a proper design of experiments scheme, we can create the design of experiments. Here, we simply use Sobol sequence implementation from ```SALib``` library. `create_doe` is a simple interface between `f3dasm` and `SALib`.\n",
    "\n",
    "The design of experiments is stored in a ```pandas.DataFrame```. This is a convenient way for the subsequent application of Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = create_doe(n_pts, doe_variables, sample_strat='sobol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated DoE for the first `n` points is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "s = 10\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(points.iloc[:n, 0], points.iloc[:n, 1], s=s, c=points.iloc[:n, 2],\n",
    "          cmap=plt.cm.coolwarm)\n",
    "plt.xlabel('$\\\\frac{d}{D_1}$')\n",
    "plt.ylabel('$\\\\frac{P}{D}$')\n",
    "clb = plt.colorbar()\n",
    "clb.ax.set_title('$\\\\frac{D_1 - D_2}{D_1}$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The supercompressible problem is *special*, in the way there's an additional variable that is not fixed nor controlled by the design of experiments scheme: **imperfections**. For `f3dasm`, these type of variables are considered `additional_variables` are are provided through a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "deg2rad = np.pi / 180\n",
    "m = 4. * deg2rad  # mean\n",
    "s = 1.2 * deg2rad  # std\n",
    "sigma = np.sqrt(np.log(s**2 / m**2 + 1))\n",
    "mu = np.log((m**2) / np.sqrt(s**2 + m**2))\n",
    "imperfection_dist = {'mean': mu, 'sigma': sigma}\n",
    "np.random.seed(seed)\n",
    "imperfections = np.random.lognormal(size=n_pts, **imperfection_dist)\n",
    "\n",
    "additional_variables = {'imperfection': imperfections}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulations metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to provide numerical simulations metadata, i.e. information that about the location of the required functions to run and post-process the numerical models, additional arguments for the models, etc.\n",
    "\n",
    "This step is quite straightforward.\n",
    "\n",
    "For each simulation, we have to provide a name (`name`), the location of the function used to create the numerical model (`abstract_model`), information about the job that contains at least the job name (`job_info`) and, optionally, the location of the post processing function (`post_processing_fnc`).\n",
    "\n",
    "Then, we just have to order the simulations (`sim_info`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_info_buckle = create_sim_info(\n",
    "    name='SUPERCOMPRESSIBLE_LIN_BUCKLE',\n",
    "    abstract_model='abaqus_modules.supercompressible_fnc.lin_buckle',\n",
    "    job_info={'name': 'Simul_supercompressible_lin_buckle'},\n",
    "    post_processing_fnc='abaqus_modules.supercompressible_fnc.post_process_lin_buckle')\n",
    "\n",
    "sim_info_riks = create_sim_info(\n",
    "    name='SUPERCOMPRESSIBLE_RIKS',\n",
    "    abstract_model='abaqus_modules.supercompressible_fnc.riks',\n",
    "    job_info={'name': 'Simul_supercompressible_riks'},\n",
    "    post_processing_fnc='abaqus_modules.supercompressible_fnc.post_process_riks')\n",
    "\n",
    "sim_info = [sim_info_buckle, sim_info_riks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main file creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we gather all the information created previously and create the main file, which is a file that contains everything that is necessary to apply the data-driven framework.\n",
    "\n",
    "Before, we can also store extra data (e.g. metadata of the problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_info = {'imperfection_dist': imperfection_dist,\n",
    "                   'seed': seed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_main_file(example_name, doe_variables, points, sim_info,\n",
    "                 fixed_variables=fixed_variables,\n",
    "                 additional_variables=additional_variables,\n",
    "                 additional_info=additional_info,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run and post-process simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's open the created file and see what it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(example_name, 'DoE.pkl'), 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the running step, the field `run_info` is of great importance, because it gives information about the simulations that are still missing or were already run (both successfully or with errors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['run_info'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the simulations through `run_sims`. We can control the simulations we want to run or choose to run the first `n_sims`.\n",
    "\n",
    "We can also use parallel computating to run several simulations simultaneously (only allowed if each simulation uses only one cpu). In that case, a `jupyter notebook` may not be the most appropriate tool because all the code has necessarily to be within the condition `if __name__ == '__main__'`. e.g.:\n",
    "```python\n",
    "from f3dasm.abaqus.run.utils import run_sims\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # (...)\n",
    "    \n",
    "    run_sims(example_name)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we provide a post-processing function (that simply accesses the simulation data and post-process it to be ameanable for the Machine Learning step), then the running step will finish only after updating the DoE with the quantities of interest.\n",
    "\n",
    "All the raw data is concatenated in a file and we can control if we keep the original folders or simply delete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_sims(example_name, points=[0], abaqus_path='abaqus',\n",
    "         keep_odb=True, pp_fnc=get_results,\n",
    "         raw_data_filename='raw_data.pkl', delete=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see next, the DoE was updated with the output variables and some simulations are now considered `successful_sims`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(example_name, 'DoE.pkl'), 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "print(data['run_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['points'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `f3dasm` we can also perform a statistic analysis of the running times (that may be useful to identify weak points in the numerical simulation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_times(example_name, raw_data_filename='raw_data.pkl');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
