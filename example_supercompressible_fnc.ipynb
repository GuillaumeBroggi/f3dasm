{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supercompressible (3d)\n",
    "\n",
    "L. F. Pereira (lfpereira@fe.up.pt)\\\n",
    "September 7, 2020\n",
    "\n",
    "\n",
    "This notebook creates the **design of experiments** and the metadata required to run the **numerical simulations**.\n",
    "\n",
    "**Note**: the parametric `Abaqus` scripts were created using `F3DAS` implementations. You can also create your own functions and use them within this framework!\n",
    "\n",
    "**TODO**: \n",
    "* add notebooks are not the best tool to run this (use script), but this intends to show how to use the tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# standard library\n",
    "import os\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "# third-party\n",
    "import numpy as np\n",
    "from SALib.sample import sobol_sequence\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# local library\n",
    "from f3das.run.utils import create_main_file\n",
    "from f3das.run.utils import create_sim_info\n",
    "from f3das.run.utils import get_sims_info\n",
    "from f3das.run.stats import analyze_times\n",
    "from f3das.abaqus.run.utils import run_sims\n",
    "from f3das.post_processing.utils import post_process_sims\n",
    "from f3das.post_processing.supercompressible import get_results\n",
    "from f3das.post_processing.utils import concatenate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define the directory name and the number of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_name = 'example_0_1'\n",
    "\n",
    "n_pts = 10  # number of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "try:\n",
    "    shutil.rmtree(example_name)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick verification of the chosen name will be performed to avoid overriding existing folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(example_name):\n",
    "    raise Exception('Name already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**TODO**\n",
    "* What is F3DAS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design of experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to define the problem.\n",
    "\n",
    "Let's define the **variables of the problem**, both the variables that are defined by the design of experiments scheme and the fixed variables (i.e. the variables that are common for all simulations).\n",
    "\n",
    "**Note**: the use of an ```OrderedDict``` is not mandatory, but forces variable order in the ```Pandas``` frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doe_variables = OrderedDict({'ratio_d': [0.004, 0.073],\n",
    "                             'ratio_pitch': [.25, 1.5],\n",
    "                             'ratio_top_diameter': [0., 0.8]})\n",
    "fixed_variables = {'n_longerons': 3,\n",
    "                   'bottom_diameter': 100.,\n",
    "                   'young_modulus': 3500.,\n",
    "                   'shear_modulus': 1287.,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_inputs_supercompressible(inputs):\n",
    "    # initialization\n",
    "    normalize_by_diameter = ['pitch', 'd']\n",
    "    normalize_by_diameter_diff = ['top_diameter']\n",
    "    \n",
    "    # get new variables\n",
    "    bottom_diameter = inputs['bottom_diameter']\n",
    "    young_modulus = inputs['young_modulus']\n",
    "    new_inputs = {}\n",
    "    for var_name, variable in inputs.items():\n",
    "        if var_name[0:5] == 'ratio':\n",
    "\n",
    "            _, var_name = var_name.split('_', 1)\n",
    "            if var_name in normalize_by_diameter:\n",
    "                variable *= bottom_diameter\n",
    "            elif var_name in normalize_by_diameter_diff:\n",
    "                variable = bottom_diameter * (1 - variable)\n",
    "\n",
    "        new_inputs[var_name] = variable\n",
    "    \n",
    "    return new_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The supercompressible problem is *special*, in the way there's an additional variable that is not fixed nor controlled by the design of experiments scheme: **imperfections**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "deg2rad = np.pi / 180\n",
    "m = 4. * deg2rad  # mean\n",
    "s = 1.2 * deg2rad  # std\n",
    "sigma = np.sqrt(np.log(s**2 / m**2 + 1))\n",
    "mu = np.log((m**2) / np.sqrt(s**2 + m**2))\n",
    "imperfection_dist = {'mean': mu, 'sigma': sigma}\n",
    "imperfections = np.random.lognormal(size=n_pts, **imperfection_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important step is the definition of the information related with the numerical simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_model = ['abaqus_modules.supercompressible_fnc.lin_buckle',\n",
    "                  'abaqus_modules.supercompressible_fnc.riks']\n",
    "# TODO: change name\n",
    "sim_info = OrderedDict({'SUPERCOMPRESSIBLE_LIN_BUCKLE':\n",
    "                        {'job_info': {'name': 'Simul_supercompressible_lin_buckle',\n",
    "                                      'description': ''}},\n",
    "                        'SUPERCOMPRESSIBLE_RIKS':\n",
    "                        {'job_info': {'name': 'Simul_supercompressible_riks',\n",
    "                                      'description': ''}}})\n",
    "post_processing_fnc = ['abaqus_modules.supercompressible_fnc.post_process_lin_buckle',\n",
    "                       'abaqus_modules.supercompressible_fnc.post_process_riks']\n",
    "\n",
    "sim_info = create_sim_info(abstract_model=abstract_model, sim_info=sim_info,\n",
    "                           post_processing_fnc=post_processing_fnc,\n",
    "                           transform_inputs=transform_inputs_supercompressible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract_model': ['abaqus_modules.supercompressible_fnc.lin_buckle', 'abaqus_modules.supercompressible_fnc.riks'], 'sim_info': OrderedDict([('SUPERCOMPRESSIBLE_LIN_BUCKLE', {'job_info': {'name': 'Simul_supercompressible_lin_buckle', 'description': ''}}), ('SUPERCOMPRESSIBLE_RIKS', {'job_info': {'name': 'Simul_supercompressible_riks', 'description': ''}})]), 'post_processing_fnc': ['abaqus_modules.supercompressible_fnc.post_process_lin_buckle', 'abaqus_modules.supercompressible_fnc.post_process_riks'], 'transform_inputs': <function transform_inputs_supercompressible at 0x000002C07B7F8EE0>}\n"
     ]
    }
   ],
   "source": [
    "print(sim_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation definition is quite straightforward.\n",
    "\n",
    "First, we need to define the `abstract_model`. That is, the class that is initialized given the variables values and contains all the methods required to successfully create, run and post-process the numerical model.\n",
    "\n",
    "Second, we need to define the specific parameters of each simulation. In this example, there's a first simulation that performs a linear buckling analysis and another that performs a riks analysis. The second simulation depends on the results of the first. The use of an `OrderedDict` is of great importance to guarantee the right order of the simulations. `job_info` is the fundamental key and has to be always defined.\n",
    "\n",
    "Finally, we define also a transformation of inputs. This is simply a mapping from the variables used in the design of experiments to the variables required to create the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using a proper design of experiments scheme, we can create the design of experiments. Here, we simply use Sobol sequence implementation from ```SALib``` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = len(doe_variables)\n",
    "points_sobol = sobol_sequence.sample(n_pts, dim)\n",
    "for i, lims in enumerate(doe_variables.values()):\n",
    "    points_sobol[:, i] = points_sobol[:, i] * (lims[1] - lims[0]) + lims[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we store the information in a dictionary and save it. Note the design of experiments is stored in a ```Pandas.DataFrame```. This is a convenient way for the subsequent application of Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doe_variables_ls = list(doe_variables.keys())\n",
    "points = pd.DataFrame(points_sobol, columns=doe_variables_ls)\n",
    "additional_variables = {'imperfection': imperfections}\n",
    "additional_info = {'imperfection_dist': imperfection_dist,\n",
    "                   'seed': seed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_main_file(example_name, doe_variables, points, sim_info,\n",
    "                 fixed_variables=fixed_variables,\n",
    "                 additional_variables=additional_variables,\n",
    "                 additional_info=additional_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's open the created file and see what it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['doe_variables', 'points', 'sim_info', 'run_info', 'version', 'fixed_variables', 'additional_variables', 'additional_info'])\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(example_name, 'DoE.pkl'), 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the running step, the field `run_info` is of great importance, because it gives information about the simulations that are still missing or were already run (both successfully or with errors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'missing_sims': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'running_sims': [], 'error_sims': [], 'successful_sims': []}\n"
     ]
    }
   ],
   "source": [
    "print(data['run_info'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the running we can see simulations status using `get_sims_info` (it also works before and after)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing simulations (total): 10/10 (100.0%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<f3das.utils.file_handling.InfoReport at 0x2c07b82ea30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sims_info(example_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the simulations through `run_sims`. We can control the simulations we want to run or choose to run the first `n_sims`.\n",
    "\n",
    "We can also use parallel computating to run several simulations simultaneously (only allowed if each simulation uses only one cpu). In that case, a `jupyter notebook` may not be the most appropriate tool because all the code has necessarily to be within the condition `if __name__ == '__main__'`. e.g.:\n",
    "```python\n",
    "from f3das.abaqus.run.utils import run_sims\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # (...)\n",
    "    \n",
    "    run_sims(example_name)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sims(example_name, points=[1, 2, 3], abaqus_path='abaqus',\n",
    "         keep_odb=True, dump_py_objs=False, gui=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the simulations, we collect data and store the quantities of interest in the `pandas.Dataframe` that contains the design of experiments. We have to provide a function that transforms the data collected during the simulations (contained in the key `'post-processing'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_process_sims(pp_fnc=get_results,\n",
    "                  output_variables=['coilable', 'sigma_crit', 'energy'],\n",
    "                  example_name=example_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(example_name, 'DoE.pkl'), 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "print(data['points'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it may be useful to merge all the collected information in a unique file. That's achieved using `concatenate_data`. We could also have done in an inverted way: first concatenate data and then post-process using the created dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_data(example_name, delete=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `F3DAS` we can also perform a statistic analysis of the running times (that may be useful to identify weak points in the numerical simulation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_times(example_name, raw_data='raw_data.pkl');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
